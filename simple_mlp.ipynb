{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_mlp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPhk0n5epdkpMvFXVNqdlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TakshPanchal/jax_notebooks/blob/main/simple_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement two hidden layers neural network classifier from scratch in JAX [20 Marks]\n",
        "\n",
        "- [X] Two hidden layers here means (input - hidden1 - hidden2 - output).\n",
        "- [X]  You must not use flax, optax, or any other library for this task.\n",
        "- [X]  Use MNIST dataset with 80:20 train:test split.\n",
        "- [X]  Manually optimize the number of neurons in hidden layers.\n",
        "- [X]  Use gradient descent from scratch to optimize your network. You should use the Pytree concept of JAX to do this elegantly.\n",
        "- [X]  Plot loss v/s iterations curve with matplotlib.\n",
        "- [ ]  Evaluate the model on test data with various classification metrics and briefly discuss their implications.\n"
      ],
      "metadata": {
        "id": "0wp4EsyoYG5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two hidden layered neural network or Multi Layered Percepron"
      ],
      "metadata": {
        "id": "xBdWnf42VE-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will cover implementation of simple neural network with hidden layers or multilayer perceptron(MLP). MNIST dataset will be used to train the network. These are the topics which will be covered\n",
        "- Loading of MNIST dataset\n",
        "- Implementation of MLP in JAX library\n",
        "- Implementation Gradient Decend algorithm\n",
        "- Analysis of loss v/s epochs curve\n",
        "- Evaluvate model will various classification metrics"
      ],
      "metadata": {
        "id": "JiF_Ru9OVotU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages\n",
        "\n",
        "Let's first import all the packages which will be needed.\n",
        "\n",
        "- `jax` is Autograd and XLA, brought together for high-performance machine learning research.\n",
        "- We will use `jax.numpy` api for calculations. \n",
        "- `matplotlib` is a library to plot graphs in Python.\n",
        "- `tqdm` tqdm is a library which is used for creating Progress Bars\n",
        "- we will use `sklearn` for train-test split and data loading\n",
        "- `seed` is used to keep all the random function calls consistent.\n"
      ],
      "metadata": {
        "id": "JaXodz4Dl6tn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "KfPyDss_YB3p"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from jax import grad, jit, vmap, random\n",
        "from tqdm import trange\n",
        "from sklearn.datasets import load_digits # for loading MNIST dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 82"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading MNIST dataset\n",
        "\n",
        "The MNIST dataset contains images of labeled handwritten digits.It is an extremely good dataset for people who want to try machine learning techniques on real-world data while spending minimal time and effort on data preprocessing and formatting. `sklearn` library's `load_digits` function helps load the images and labels directly as `numpy` array.\n",
        "\n",
        "`load_digits` function returns a `dict` which contains metadata and data of datasets. Use `'images'` and `'target'` keys to get images and labels "
      ],
      "metadata": {
        "id": "AHksiez4awXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = load_digits() # returns dictionary\n",
        "print(mnist.keys())\n",
        "\n",
        "# Description of mnist dataset\n",
        "# print(mnist['DESCR']) "
      ],
      "metadata": {
        "id": "PVY0YjSzNlOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a43bed-cd37-47aa-d42b-c28c9834f6d9"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = mnist['images']\n",
        "labels = mnist['target']\n",
        "\n",
        "n_images = images.shape[0]\n",
        "im_shape = images[0].shape\n",
        "n_classes = len(mnist['target_names'])\n",
        "print(\"Total no. of images are \", n_images)\n",
        "print(\"Shape of a image is\",im_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVn3917acOR8",
        "outputId": "899d9d37-697a-4aff-ad70-2349f6621a3c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of images are  1797\n",
            "Shape of a image is (8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see some images by running next cell. "
      ],
      "metadata": {
        "id": "J14SSG0CeImO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 10, figsize=(10, 6))\n",
        "for i in range(20):\n",
        "    axes[i//10, i %10].imshow(mnist.images[i], cmap='gray');\n",
        "    axes[i//10, i %10].axis('off')\n",
        "    axes[i//10, i %10].set_title(f\"target: {mnist.target[i]}\")\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "QZ43UUuMwZy_",
        "outputId": "e3ccc3f4-7f45-499c-c312-1929448969fb"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that each image is made of pixels and a image can be represeted as a matrix. Bellow image is a close look of a grayscale image. Each pixel is has a value which represents it's brightness. This image can be represented as a 2-d matrix.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.saraai.com/images/blog/mnist1.png\" />\n",
        "</p>\n",
        "In our dataset, we have grayscale images of 8X8 pixels."
      ],
      "metadata": {
        "id": "_NQ25U6kfdj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data in train and test\n",
        "\n",
        "The train-test split technique is used to evaluate model performance after training. \n",
        "\n",
        "The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.\n",
        "\n",
        "- **Train Dataset**: Used to fit the machine learning model.\n",
        "\n",
        "- **Test Dataset**: Used to evaluate the fit machine learning model.\n",
        "The objective is to estimate the performance of the machine learning model on \n",
        "- **unseen data**: data not used to train the model.\n",
        "\n",
        "In practice, model is expected for prediction on new unseen data. That is why we make a subset of unseen data for evaluation of model.\n",
        "\n",
        "Here we are doing 80:20 split for train and test data\n",
        "\n"
      ],
      "metadata": {
        "id": "VEcJxUTZhxMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=seed)\n",
        "# images = images.reshape(n_images,-1)\n",
        "# images = (images - images.min()) / (images.max() - images.min())\n",
        "print(\"Train size : \",X_train.shape[0])\n",
        "print(\"Test size  : \",X_test.shape[0])"
      ],
      "metadata": {
        "id": "kWWvM68Hvxqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd96198-4945-4a63-f8a0-97f2eed88ca7"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size :  1437\n",
            "Test size  :  360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi Layer Perceptron"
      ],
      "metadata": {
        "id": "ycoX18q_9iKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before moving to implementation let us remember some concepts of Multilayer perceptron(MLP). \n",
        "\n",
        "MLP is feedforward neural network which has structure like this. It contains input,output and some hidden layers which may have different dimensions. It can be used for classfication as well as regression problem\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://nasirml.files.wordpress.com/2017/12/mlp2_model.png?w=585&h=272\" />\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "This is image of neural network of two hidden layers. The first layer is called **Input layer** which consists data from the sample. Also, input layer does not contain any paramers. The last layer is **Output layer** which is prediction of the network.\n",
        "Different arrow represents linear tranformation followed by non-linear activation. </p>\n",
        "<p> \n",
        "Input layer dimensions are decided from the shape of input data and Output layer dimensions are decided based on the number of labels or classes. Hidden layer dimensions are hyperparameters and can be changed on base of model performance.\n",
        "</p>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Linear Transformation can be defined by following equation.\n",
        "\n",
        "\n",
        "$$Z^{[l]} = W^{[l]} \\cdot A^{[l-1]} +b^{[l]}\\tag{1}$$\n",
        "\n",
        "where \n",
        "$A^{[0]} = X$ and Superscript $[l]$ denotes a quantity associated with the $l^{th}$ layer \n",
        "\n",
        "In this equation $W$ is known as weight and $b$ is bias."
      ],
      "metadata": {
        "id": "TJ2HCGvB9m23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For one dimention Eq. $(1)$ can be simplify as equation of line which we have already studied. \n",
        "\n",
        "$$y=w ⋅ x + b\\tag{2}$$\n",
        "\n",
        "So, now you understand that you recall linear transformation, let's understand about non-linear activation"
      ],
      "metadata": {
        "id": "azYM0Ut6DryM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Function**\n",
        "As I mentioned before, activation functions are basically non-linear transformation applied after linear tranformation. After applying activation output will be send to next layer of neurons or it may be the final prediction.\n",
        "\n",
        "There are different type of activation functions but most common activation functions used in Deep Learning are mentioned bellow:\n",
        "- [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n",
        "- [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)\n",
        "- [softmax](https://en.wikipedia.org/wiki/Softmax_function)\n",
        "- tanh\n",
        "\n",
        "Activation functions adds non-linearity which helps to learn more complex patterns in the data. Each activation function mentioned here has certain use cases. We will use ReLU and softmax for our MLP model. You will learn more about those later. \n"
      ],
      "metadata": {
        "id": "ZXxbwvJIEsvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type of problem**\n",
        "We also have to identify that which type of problem is this. Is it a classfication problem or regression? if it is classfication then, Is it a binary or multi-class or multi-label?\n",
        "\n",
        "we know that we have to predict a discreate number from a image which means we have to classify the images. So that this is a classfication problem\n",
        "\n",
        "**binary classification** - no. of classes will be only two\n",
        "\n",
        "**multi-class classfication** - no. of classes are more than two and each sample maps to only one class\n",
        "\n",
        "**multi-lable classification** - no. of classes are more than two and each sample may maps to more than one classes\n",
        "\n",
        "\n",
        "In our dataset, each image correspondence to a number so we are dealing with **multi-class classification problem**."
      ],
      "metadata": {
        "id": "kTBDOs8QISh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Model"
      ],
      "metadata": {
        "id": "okRrNeXgk5Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first, we have to define parameters of the model i.e. weights and biases for each layer. Remember input layer does not have any parameters."
      ],
      "metadata": {
        "id": "WLh6Jz_vl0mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(layer_sizes,seed=42):\n",
        "    \"\"\"\n",
        "    Initiate parameters of MLP model.\n",
        "\n",
        "    Arguments:\n",
        "    layer_sizes -- list of sizes of layers starting from input layer to output layer\n",
        "    seed -- interger, seed for random number generation\n",
        "    \n",
        "    Returns:\n",
        "    params -- pytree of weights and biases of the layers\n",
        "    \"\"\"\n",
        "    n_layers = len(layer_sizes)\n",
        "    parent_key = random.PRNGKey(seed)\n",
        "    params = []\n",
        "    keys = random.split(parent_key,num = n_layers - 1)  \n",
        "\n",
        "    for i in range(n_layers-1):\n",
        "        w_key,b_key = random.split(keys[i])\n",
        "        in_size = layer_sizes[i]\n",
        "        out_size = layer_sizes[i+1]\n",
        "\n",
        "        weights = random.normal(w_key,shape=(in_size, out_size))\n",
        "        biases = random.normal(b_key,shape=(out_size,))\n",
        "        params.append(dict(weights=weights,biases=biases))\n",
        "    return params\n"
      ],
      "metadata": {
        "id": "YBkR6gpGCT1W"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(params, x):\n",
        "    \"\"\"\n",
        "        forward propagation for a single sample\n",
        "\n",
        "        Arguments:\n",
        "        params -- parameters pytree of the model\n",
        "        x -- numpy feature vector of a sample\n",
        "\n",
        "        Returns:\n",
        "        output -- post activation value of last layer\n",
        "    \"\"\"\n",
        "    activation = x  # x will be input for next hidden layer\n",
        "\n",
        "    hidden_layers = params[:-1] \n",
        "\n",
        "    # Loop over the hidden layers with ReLU activation\n",
        "    for layer in hidden_layers:\n",
        "        z = np.dot(activation, layer['weights']) + layer['biases']\n",
        "        activation = jax.nn.relu(z)\n",
        "\n",
        "    # Perform final transformation with softmax activation\n",
        "    last_layer = params[-1]\n",
        "    logits = np.dot(activation, last_layer['weights']) + last_layer['biases']\n",
        "    output = jax.nn.log_softmax(logits)\n",
        "\n",
        "    return output\n",
        "\n",
        "batch_forward = jit(vmap(forward, in_axes=(None, 0))) # forward propagation for a batch\n"
      ],
      "metadata": {
        "id": "dC_96qWyCk_O"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def loss_fn(params, X, Y):\n",
        "    \"\"\" Compute the multi-class cross-entropy loss \"\"\"\n",
        "    prediction = batch_forward(params, X)\n",
        "    return -np.sum(Y * prediction)\n"
      ],
      "metadata": {
        "id": "vIUPwpyDCxVU"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def grad_calculation(params, X, Y):\n",
        "    \"\"\"calculate gradients of parameters\n",
        "\n",
        "    Args:\n",
        "        params (list): parameters of the model\n",
        "        X (array type): input matrix of batch which has shape (n_samples, n_features)\n",
        "        Y (array type): one hot encoded true matrix of shape (n_samples, n_)\n",
        "\n",
        "    Returns:\n",
        "        list: gradients of parameters\n",
        "    \"\"\"\n",
        "    gradients = jax.grad(loss_fn)(params, X, Y)\n",
        "    return gradients\n",
        "\n",
        "def update_param(p,g,lr = 1e-5):\n",
        "    \"\"\"update parameters of the model\n",
        "\n",
        "    Args:\n",
        "        p (array like): matrix of a parameter\n",
        "        g (array like): gradient of the same parameter\n",
        "        lr (float, optional): learning rate. Defaults to 1e-5.\n",
        "\n",
        "    Returns:\n",
        "        array like: updated parameter matrix\n",
        "    \"\"\"\n",
        "    return p - lr * g\n",
        "\n",
        "@jit\n",
        "def gradient_decend(params,gradients):\n",
        "    \"\"\"Gradient decend algorithm which minimizes loss by updating parameters.\n",
        "\n",
        "    Args:\n",
        "        params (list): parameters of the model\n",
        "        gradients (list): gradients of parameters\n",
        "\n",
        "    Returns:\n",
        "        array like: updated parameters\n",
        "    \"\"\"\n",
        "    return jax.tree_map(\n",
        "        update_param,\n",
        "        params, gradients\n",
        "    )\n"
      ],
      "metadata": {
        "id": "qtQnKT1hR5iV"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(params, X):\n",
        "    \"\"\"predicts class from the sample.\n",
        "\n",
        "    Args:\n",
        "        params (list): parameters of the model\n",
        "        X (array like): Input feaure matrix of a sample or a batch having shape (n_samples, n_features)\n",
        "\n",
        "    Returns:\n",
        "        array like: predicted class matrix having shape of (n_samples, n_classes)\n",
        "    \"\"\"\n",
        "    predictions = batch_forward(params,X)\n",
        "    labels = np.argmax(predictions, axis=-1)\n",
        "    return labels\n",
        "\n",
        "def accuracy(params, X, Y):\n",
        "    \"\"\"accuracy metric for classfication model\n",
        "\n",
        "    Args:\n",
        "        params (list): parameters of the model\n",
        "        X (array like): Input feaure matrix of a sample or a batch having shape (n_samples, n_features)\n",
        "        Y (array like): True class labels matrix having shape of (n_samples, n_classes)\n",
        "\n",
        "    Returns:\n",
        "        float: accuracy of the model on given data\n",
        "    \"\"\"\n",
        "    Y_hat = predict(params, X)\n",
        "    return np.mean(Y == Y_hat)\n"
      ],
      "metadata": {
        "id": "DshSdJNLi0MB"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "Yizb8-q7P2tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_images, train_labels, params, epochs = 10, batch_size = 256):\n",
        "    \"\"\"traing loop for MLP model\n",
        "\n",
        "    Args:\n",
        "        train_images (array like): numpy array of train data images\n",
        "        train_labels (numpy array): array of train labels\n",
        "        params (_type_): _description_\n",
        "        epochs (int, optional): number of epochs for the training. Defaults to 10.\n",
        "        batch_size (int, optional): batch size for training. Defaults to 256.\n",
        "    Returns:\n",
        "        list: trained parameters of the model\n",
        "    \"\"\"\n",
        "    # print(params)\n",
        "    n_samples = train_images.shape[0]\n",
        "    train_losses = []\n",
        "    \n",
        "    # loop over epochs\n",
        "    for _ in trange(epochs):\n",
        "        total_loss = 0  # total loss per epoch\n",
        "        # loop over batches\n",
        "        for batch_i in range(0, n_samples, batch_size):\n",
        "            # slice batch data\n",
        "            batch_end_idx = batch_i + batch_size if not batch_i + batch_size > n_samples + 1 else -1\n",
        "            batch_images = train_images[batch_i: batch_end_idx]\n",
        "            batch_labels = train_labels[batch_i: batch_end_idx]            \n",
        "\n",
        "            # push NumPy explicitly to GPU\n",
        "            batch_images = jax.device_put(batch_images) \n",
        "            batch_labels = jax.device_put(batch_labels)\n",
        "\n",
        "            loss = loss_fn(params, batch_images, batch_labels) \n",
        "            grads = grad_calculation(params, batch_images, batch_labels)\n",
        "            params = gradient_decend(params,grads)\n",
        "            \n",
        "            total_loss += loss\n",
        "\n",
        "        train_losses.append(total_loss)\n",
        "\n",
        "    return params, train_losses\n"
      ],
      "metadata": {
        "id": "QbXq8v7TViPj"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(eval_images,true_labels, params):\n",
        "    \"\"\"evaluate model on a give data\n",
        "\n",
        "    Args:\n",
        "        eval_images (array like): array of evaluation data images of shape (n_samples, n_features)\n",
        "        true_labels (_type_): True class labels matrix having shape of (n_samples, 1)\n",
        "        params (list): parameters of the model\n",
        "    Returns:\n",
        "        loss (float) : Loss for the given data\n",
        "        accuracy (float): Accuracy for the given data\n",
        "    \"\"\"\n",
        "    y_train_encoded = jax.nn.one_hot(y_train, n_classes)\n",
        "    eval_loss = loss_fn(params, eval_images, y_train_encoded)\n",
        "    \n",
        "    eval_accuracy = accuracy(params, eval_images, true_labels)\n",
        "    \n",
        "    print(\"Accuracy of the model is \", eval_accuracy)\n",
        "    print(\"Loss of the model is \", eval_loss)\n",
        "    return eval_loss, eval_accuracy \n"
      ],
      "metadata": {
        "id": "9WMDl13ObGMC"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "batch_size = 256\n",
        "n_features = im_shape[0] * im_shape[1]\n",
        "layers = [n_features, 32, 32, n_classes]\n",
        "\n",
        "params = init_params(layers,42)  \n",
        "print(\"Layers shapes are - \", jax.tree_map(lambda p: p.shape,params))\n",
        "\n",
        "X_train_flattern = X_train.reshape(-1, n_features) # one hot encode labels encode labels \n",
        "y_train_encoded = jax.nn.one_hot(y_train, n_classes) # flattern inputs \n",
        "\n",
        "params, loss_train = train(X_train_flattern, y_train_encoded, params, epochs = epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnCojJVOOvK",
        "outputId": "9f4b9dee-f5c5-4de8-e416-5573d45ce3c8"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers shapes are -  [{'biases': (32,), 'weights': (64, 32)}, {'biases': (32,), 'weights': (32, 32)}, {'biases': (10,), 'weights': (32, 10)}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:18<00:00, 53.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss, eval_acc = evaluate(X_train_flattern, y_train, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9_0NWLIh2c2",
        "outputId": "16313aef-0c66-4a3c-9ceb-2b25b40c8119"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is  1.0\n",
            "Loss of the model is  0.11724136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(1, epochs + 1)\n",
        "plt.plot(epochs_range, loss_train, 'g', label='Training loss')\n",
        "# plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fVoGbFmPbGF0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b3b713f5-187d-4191-f937-78ecd411c140"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QX-8UXtsbGC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ac249f-71e3-4558-a0b4-7e0dc5c315f1"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(epochs_range)"
      ],
      "metadata": {
        "id": "g89G1CgubFyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb31bd1b-f17c-444d-82fa-1caef4e9e6bf"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def MLPClassfier():\n",
        "#     def __init__(self,layer_sizes,seed):\n",
        "#         self.parent_key = random.PRNGKey(seed)\n",
        "#         self.params = []\n",
        "#         self.layer_sizes = layer_sizes\n",
        "#         self.n_layers = len(self.layer_sizes)\n",
        "#         self._init_params()\n",
        "#         self.caches = []\n",
        "\n",
        "#     def _init_params(self,scale = 0.01):\n",
        "#         keys = random.split(self.parent_key,num = self.n_layers - 1)\n",
        "\n",
        "#         for i in range(self.n_layers-1):\n",
        "#             w_key,b_key = random.split(keys[i])\n",
        "#             in_size = self.layer_sizes[i]\n",
        "#             out_size = self.layer_sizes[i+1]\n",
        "\n",
        "#             w = random.normal(w_key,shape=(in_size,out_size))\n",
        "#             b = random.normal(b_key,shape=(out_size,))\n",
        "#             self.params.append([w,b])\n",
        "\n",
        "#     def _linear_forward(self,activation,w,b):\n",
        "#         \"\"\"\n",
        "#             for a single sample\n",
        "#         \"\"\"\n",
        "#         z = np.dot(w,activation) + b \n",
        "#         cache = (activation,w,b)\n",
        "#         return z, cache\n",
        "    \n",
        "#     def _linear_activation_forward(self,activation, w, b, activation_fn):\n",
        "#         z, linear_cache = self._linear_forward(activation, w, b)\n",
        "#         activation = activation_fn(z)\n",
        "#         cache = (linear_cache, z)\n",
        "\n",
        "#         return activation, cache\n",
        "\n",
        "#     @jit\n",
        "#     def _forward(self,x):\n",
        "#         \"\"\"\n",
        "#         forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
        "        \n",
        "#         Arguments:\n",
        "#         X -- data, numpy array of shape (input size, number of examples)\n",
        "#         parameters -- output of initialize_parameters_deep()\n",
        "        \n",
        "#         Returns:\n",
        "#         AL -- last post-activation value\n",
        "#         caches -- list of caches containing:\n",
        "#                     every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
        "#                     the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
        "#         \"\"\"\n",
        "\n",
        "       \n",
        "#         activation = x\n",
        "#         # self.\n",
        "#         L = self.n_layers                # number of layers in the neural network\n",
        "    \n",
        "\n",
        "#         hidden_layers = params[:-1]\n",
        "\n",
        "#         # Loop over the ReLU hidden layers\n",
        "#         for w, b in hidden_layers:\n",
        "#             activation, cache = self._linear_activation_forward(activation, w, b, activation_fn = jax.nn.relu)\n",
        "#             self.caches.append(cache)\n",
        "\n",
        "#         # Perform final trafo to logits\n",
        "#         final_w, final_b = params[-1]\n",
        "#         logits = np.dot(final_w, activation) + final_b\n",
        "#         output, cache = self._linear_activation_forward(activation, final_w, final_b, activation_fn = jax.nn.softmax)\n",
        "#         output = jax.nn.softmax(logits)\n",
        "#         self.caches.append(cache)\n",
        "\n",
        "#         return output\n",
        "\n",
        "#     def forward(self,X):\n",
        "#         batch_forward = jit(vmap(self._forward, in_axes=(None, 0), out_axes=0))\n",
        "#         return batch_forward(X)\n",
        "\n",
        "#     def linear_backward(self, dZ, cache):\n",
        "#         \"\"\"\n",
        "#         Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "#         Arguments:\n",
        "#         dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "#         cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "\n",
        "#         Returns:\n",
        "#         dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "#         dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "#         db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "#         \"\"\"\n",
        "#         A_prev, W, b = cache\n",
        "#         m = A_prev.shape[1]\n",
        "\n",
        "#         ### START CODE HERE ### (≈ 3 lines of code)\n",
        "#         dW = np.dot(dZ, cache[0].T) / m\n",
        "#         db = np.squeeze(np.sum(dZ, axis=1, keepdims=True)) / m\n",
        "#         dA_prev = np.dot(cache[1].T, dZ)\n",
        "#         ### END CODE HERE ###\n",
        "        \n",
        "#         assert (dA_prev.shape == A_prev.shape)\n",
        "#         assert (dW.shape == W.shape)\n",
        "#         assert (isinstance(db, float))\n",
        "        \n",
        "#         return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "-fj3-RY18knO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "@jit\n",
        "def forward(params,in_array):\n",
        "    \"\"\"\n",
        "        Compute the forward pass for each example individually\n",
        "        params: list of weights and biases of MLP \n",
        "        x: single flat image\n",
        "    \"\"\"\n",
        "    hidden_layers = params[:-1]\n",
        "\n",
        "    activations = in_array\n",
        "\n",
        "    # Loop over the ReLU hidden layers\n",
        "    for w, b in hidden_layers:\n",
        "        a = np.dot(w,activations) + b \n",
        "        activation = jax.nn.relu(a)\n",
        "    \n",
        "    # Perform final trafo to logits\n",
        "    final_w, final_b = params[-1]\n",
        "    logits = np.dot(final_w, activations) + final_b\n",
        "    output = jax.nn.softmax(logits)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "oilnpAgI5Bya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update(params,imgs,labels):\n",
        "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
        "    value, grads = value_and_grad(loss)(params, x, y)\n"
      ],
      "metadata": {
        "id": "uzSY59J_P8th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_MLPClassfier(layer_sizes,parent_key,scale = 0.01):\n",
        "    params = []\n",
        "    keys = random.split(parent_key,num= len(layer_sizes) - 1)\n",
        "\n",
        "    for i in range(len(layer_sizes)-1):\n",
        "        w_key,b_key = random.split(keys[i])\n",
        "        in_size = layer_sizes[i]\n",
        "        out_size = layer_sizes[i+1]\n",
        "        w = random.normal(w_key,shape=(in_size,out_size))\n",
        "        b = random.normal(b_key,shape=(out_size,))\n",
        "        params.append([w,b])\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "2mBJQ5mR4jWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "input,h1,h2,output = (784,512,256,10)\n",
        "layers = [input,h1,h2,output]\n",
        "seed = 42 \n",
        "\n",
        "parent_key = random.PRNGKey(seed)\n",
        "MLP_params = init_MLPClassfier(layers,parent_key)\n",
        "\n",
        "print(jax.tree_map(lambda x: x.shape,MLP_params))"
      ],
      "metadata": {
        "id": "Xw5CXGtK41Zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}