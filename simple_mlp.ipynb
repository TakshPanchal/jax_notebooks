{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_mlp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8NQqTdLi/ABFaMbQ1aGjl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TakshPanchal/jax_notebooks/blob/main/simple_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement two hidden layers neural network classifier from scratch in JAX [20 Marks]\n",
        "\n",
        "- [ ] Two hidden layers here means (input - hidden1 - hidden2 - output).\n",
        "- [X]  You must not use flax, optax, or any other library for this task.\n",
        "- [X]  Use MNIST dataset with 80:20 train:test split.\n",
        "- [ ]  Manually optimize the number of neurons in hidden layers.\n",
        "- [ ]  Use gradient descent from scratch to optimize your network. You should use the Pytree concept of JAX to do this elegantly.\n",
        "- [ ]  Plot loss v/s iterations curve with matplotlib.\n",
        "- [ ]  Evaluate the model on test data with various classification metrics and briefly discuss their implications.\n"
      ],
      "metadata": {
        "id": "0wp4EsyoYG5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two hidden layered neural network or Multi Layered Percepron"
      ],
      "metadata": {
        "id": "xBdWnf42VE-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will cover implementation of simple neural network with hidden layers or multilayer perceptron(MLP). MNIST dataset will be used to train the network. These are the topics which will be covered\n",
        "- Loading of MNIST dataset\n",
        "- Implementation of MLP in JAX library\n",
        "- Implementation Gradient Decend algorithm\n",
        "- Analysis of loss v/s epochs curve\n",
        "- Evaluvate model will various classification metrics"
      ],
      "metadata": {
        "id": "JiF_Ru9OVotU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages\n",
        "\n",
        "Let's first import all the packages which will be needed.\n",
        "\n",
        "- `jax` is Autograd and XLA, brought together for high-performance machine learning research.\n",
        "- We will use `jax.numpy` api for calculations. \n",
        "- `matplotlib` is a library to plot graphs in Python.\n",
        "- `tqdm` tqdm is a library which is used for creating Progress Bars\n",
        "- we will use `sklearn` for train-test split and data loading\n",
        "- `seed` is used to keep all the random function calls consistent.\n"
      ],
      "metadata": {
        "id": "JaXodz4Dl6tn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "KfPyDss_YB3p"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from jax import grad, jit, vmap\n",
        "from tqdm import trange\n",
        "from sklearn.datasets import load_digits # for loading MNIST dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 82"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading MNIST dataset\n",
        "\n",
        "The MNIST dataset contains images of labeled handwritten digits.It is an extremely good dataset for people who want to try machine learning techniques on real-world data while spending minimal time and effort on data preprocessing and formatting. `sklearn` library's `load_digits` function helps load the images and labels directly as `numpy` array.\n",
        "\n",
        "`load_digits` function returns a `dict` which contains metadata and data of datasets. Use `'images'` and `'target'` keys to get images and labels "
      ],
      "metadata": {
        "id": "AHksiez4awXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = load_digits() # returns dictionary\n",
        "print(mnist.keys())\n",
        "\n",
        "# Description of mnist dataset\n",
        "# print(mnist['DESCR']) "
      ],
      "metadata": {
        "id": "PVY0YjSzNlOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea22d7e-68a2-4b70-e12f-fcb103df63ce"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = mnist['images']\n",
        "labels = mnist['target']\n",
        "\n",
        "n_images = images.shape[0]\n",
        "im_shape = images[0].shape\n",
        "print(\"Total no. of images are \", n_images)\n",
        "print(\"Shape of a image is\",im_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVn3917acOR8",
        "outputId": "3b6f845b-2a6e-4785-db06-afc2ccf56516"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of images are  1797\n",
            "Shape of a image is (8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see some images by running next cell. "
      ],
      "metadata": {
        "id": "J14SSG0CeImO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 10, figsize=(10, 6))\n",
        "for i in range(20):\n",
        "    axes[i//10, i %10].imshow(mnist.images[i], cmap='gray');\n",
        "    axes[i//10, i %10].axis('off')\n",
        "    axes[i//10, i %10].set_title(f\"target: {mnist.target[i]}\")\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "QZ43UUuMwZy_",
        "outputId": "c72feaad-730e-4be5-80c3-91bb4e5bef28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that each image is made of pixels and a image can be represeted as a matrix. Bellow image is a close look of a grayscale image. Each pixel is has a value which represents it's brightness. This image can be represented as a 2-d matrix.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.saraai.com/images/blog/mnist1.png\" />\n",
        "</p>\n",
        "In our dataset, we have grayscale images of 8X8 pixels."
      ],
      "metadata": {
        "id": "_NQ25U6kfdj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data in train and test\n",
        "\n",
        "The train-test split technique is used to evaluate model performance after training. \n",
        "\n",
        "The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.\n",
        "\n",
        "- **Train Dataset**: Used to fit the machine learning model.\n",
        "\n",
        "- **Test Dataset**: Used to evaluate the fit machine learning model.\n",
        "The objective is to estimate the performance of the machine learning model on \n",
        "- **unseen data**: data not used to train the model.\n",
        "\n",
        "In practice, model is expected for prediction on new unseen data. That is why we make a subset of unseen data for evaluation of model.\n",
        "\n",
        "Here we are doing 80:20 split for train and test data\n",
        "\n"
      ],
      "metadata": {
        "id": "VEcJxUTZhxMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=seed)\n",
        "# images = images.reshape(n_images,-1)\n",
        "# images = (images - images.min()) / (images.max() - images.min())\n",
        "print(\"Train size : \",X_train.shape[0])\n",
        "print(\"Test size  : \",X_test.shape[0])"
      ],
      "metadata": {
        "id": "kWWvM68Hvxqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb66cd61-fed3-403a-c7b5-9768c5a6b439"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size :  1437\n",
            "Test size  :  360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi Layer Perceptron"
      ],
      "metadata": {
        "id": "ycoX18q_9iKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilayer perceptron is feedforward neural network which has structure like this. \n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://nasirml.files.wordpress.com/2017/12/mlp2_model.png?w=585&h=272\" />\n",
        "</p>\n",
        "\n",
        "This is image of neural network of two hidden layers. The first layer is called **Input layer** which consists data from the sample. The last layer is **Output layer** which is prediction of the network."
      ],
      "metadata": {
        "id": "TJ2HCGvB9m23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Model"
      ],
      "metadata": {
        "id": "okRrNeXgk5Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WLh6Jz_vl0mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(layer_sizes,seed):\n",
        "    n_layers = len(layer_sizes)\n",
        "    parent_key = random.PRNGKey(seed)\n",
        "    params = []\n",
        "    keys = random.split(parent_key,num = n_layers - 1)\n",
        "\n",
        "    for i in range(n_layers-1):\n",
        "        w_key,b_key = random.split(keys[i])\n",
        "        in_size = layer_sizes[i]\n",
        "        out_size = layer_sizes[i+1]\n",
        "\n",
        "        W = random.normal(w_key,shape=(in_size,out_size))\n",
        "        b = random.normal(b_key,shape=(out_size,))\n",
        "        params.append(dict(weights=W,biases=b))\n",
        "    return params"
      ],
      "metadata": {
        "id": "YBkR6gpGCT1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(params,x):\n",
        "    \"\"\"\n",
        "        forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
        "\n",
        "        Arguments:\n",
        "        X -- data, numpy array of shape (input size, number of examples)\n",
        "        parameters -- output of initialize_parameters_deep()\n",
        "\n",
        "        Returns:\n",
        "        AL -- last post-activation value\n",
        "        caches -- list of caches containing:\n",
        "        every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
        "        the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
        "    \"\"\"\n",
        "    activation = x\n",
        "\n",
        "    hidden_layers = params[:-1]\n",
        "\n",
        "    # Loop over the ReLU hidden layers\n",
        "    for layer in hidden_layers:\n",
        "        z = np.dot(activation,layer['weights']) + layer['biases']\n",
        "        activation = jax.nn.relu(z)\n",
        "\n",
        "    # Perform final trafo to logits\n",
        "    last_layer = params[-1]\n",
        "    logits = np.dot(activation,last_layer['weights']) + last_layer['biases']\n",
        "    output = jax.nn.log_softmax(logits)\n",
        "\n",
        "    return output\n",
        "\n",
        "batch_forward = jit(vmap(forward, in_axes=(None, 0)))"
      ],
      "metadata": {
        "id": "dC_96qWyCk_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def loss_fn(params, X, Y):\n",
        "    \"\"\" Compute the multi-class cross-entropy loss \"\"\"\n",
        "    prediction = batch_forward(params, X)\n",
        "    return -np.sum(Y * prediction)"
      ],
      "metadata": {
        "id": "vIUPwpyDCxVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def grad_calculation(params, X, Y):\n",
        "    gradients = grad(loss_fn)(params, X, Y)\n",
        "    return gradients\n",
        "\n",
        "def update_param(p,g,lr = 1e-5):\n",
        "    return p - lr * g\n",
        "\n",
        "@jit\n",
        "def gradient_decend(parameters,gradients):\n",
        "    return jax.tree_map(\n",
        "        update_param,\n",
        "        parameters, gradients\n",
        "    )\n",
        "\n",
        "\n",
        "def predict(params, X):\n",
        "    predictions = batch_forward(params,X)\n",
        "    labels = np.argmax(batch_forward(params, X), axis=-1)\n",
        "    return labels\n",
        "\n",
        "def accuracy(params, X, Y):\n",
        "    Y_hat = predict(params, X)\n",
        "    return np.mean(Y == Y_hat)"
      ],
      "metadata": {
        "id": "DshSdJNLi0MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "Yizb8-q7P2tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "layers = [X_train.shape[-1],64,32,n]\n",
        "\n",
        "params = init_params(layers,42)\n",
        "# print(params)\n",
        "no_of_samples = X_train.shape[0]\n",
        "no_of_batches = no_of_samples // batch_size\n",
        "\n",
        "train_loss = []\n",
        "for e in trange(epochs):\n",
        "    total_loss = 0\n",
        "    acc = 0\n",
        "    for batch_i in range(0,no_of_samples,batch_size):\n",
        "        batch_end_idx = batch_i + batch_size if not batch_i + batch_size > no_of_samples + 1 else -1\n",
        "        batch_images = X_train[batch_i: batch_end_idx]\n",
        "        batch_labels = y_train[batch_i: batch_end_idx]\n",
        "        batch_labels_encoded = jax.nn.one_hot(batch_labels, len(mnist['target_names']))\n",
        "        \n",
        "        batch_images = jax.device_put(batch_images)  # push NumPy explicitly to GPU\n",
        "        batch_labels_encoded = jax.device_put(batch_labels_encoded)\n",
        "\n",
        "        loss = loss_fn(params, batch_images, batch_labels_encoded)\n",
        "        grads = grad_calculation(params, batch_images, batch_labels_encoded)\n",
        "        params = gradient_decend(params,grads)\n",
        "        total_loss += loss\n",
        "        acc += accuracy(params, batch_images, batch_labels)\n",
        "    \n",
        "    train_loss.append(total_loss)\n",
        "\n",
        "  \n",
        "    # print(\"\\nTotal loss is -\",total_loss)\n",
        "    # print(\"\\nAccuracy - \", acc/no_of_batches)\n",
        "    # epoch_range.set_description(f\"Total Loss {(total_loss)} - total Accuracy {acc/no_of_batches}\" )\n",
        "    # epoch_range.refresh() # to show immediately the update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnCojJVOOvK",
        "outputId": "9c3ef8ee-90db-4718-dba7-8f16bdc43425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 60.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3test_accuracy = accuracy(params,X_test,y_test)"
      ],
      "metadata": {
        "id": "9WMDl13ObGMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec6d1c5-155a-4f17-e59f-45e8cb1adc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.6888889, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fVoGbFmPbGF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ad12ca-0287-42a3-ab5b-fcd83430ba1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QX-8UXtsbGC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g89G1CgubFyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def MLPClassfier():\n",
        "#     def __init__(self,layer_sizes,seed):\n",
        "#         self.parent_key = random.PRNGKey(seed)\n",
        "#         self.params = []\n",
        "#         self.layer_sizes = layer_sizes\n",
        "#         self.n_layers = len(self.layer_sizes)\n",
        "#         self._init_params()\n",
        "#         self.caches = []\n",
        "\n",
        "#     def _init_params(self,scale = 0.01):\n",
        "#         keys = random.split(self.parent_key,num = self.n_layers - 1)\n",
        "\n",
        "#         for i in range(self.n_layers-1):\n",
        "#             w_key,b_key = random.split(keys[i])\n",
        "#             in_size = self.layer_sizes[i]\n",
        "#             out_size = self.layer_sizes[i+1]\n",
        "\n",
        "#             w = random.normal(w_key,shape=(in_size,out_size))\n",
        "#             b = random.normal(b_key,shape=(out_size,))\n",
        "#             self.params.append([w,b])\n",
        "\n",
        "#     def _linear_forward(self,activation,w,b):\n",
        "#         \"\"\"\n",
        "#             for a single sample\n",
        "#         \"\"\"\n",
        "#         z = np.dot(w,activation) + b \n",
        "#         cache = (activation,w,b)\n",
        "#         return z, cache\n",
        "    \n",
        "#     def _linear_activation_forward(self,activation, w, b, activation_fn):\n",
        "#         z, linear_cache = self._linear_forward(activation, w, b)\n",
        "#         activation = activation_fn(z)\n",
        "#         cache = (linear_cache, z)\n",
        "\n",
        "#         return activation, cache\n",
        "\n",
        "#     @jit\n",
        "#     def _forward(self,x):\n",
        "#         \"\"\"\n",
        "#         forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
        "        \n",
        "#         Arguments:\n",
        "#         X -- data, numpy array of shape (input size, number of examples)\n",
        "#         parameters -- output of initialize_parameters_deep()\n",
        "        \n",
        "#         Returns:\n",
        "#         AL -- last post-activation value\n",
        "#         caches -- list of caches containing:\n",
        "#                     every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
        "#                     the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
        "#         \"\"\"\n",
        "\n",
        "       \n",
        "#         activation = x\n",
        "#         # self.\n",
        "#         L = self.n_layers                # number of layers in the neural network\n",
        "    \n",
        "\n",
        "#         hidden_layers = params[:-1]\n",
        "\n",
        "#         # Loop over the ReLU hidden layers\n",
        "#         for w, b in hidden_layers:\n",
        "#             activation, cache = self._linear_activation_forward(activation, w, b, activation_fn = jax.nn.relu)\n",
        "#             self.caches.append(cache)\n",
        "\n",
        "#         # Perform final trafo to logits\n",
        "#         final_w, final_b = params[-1]\n",
        "#         logits = np.dot(final_w, activation) + final_b\n",
        "#         output, cache = self._linear_activation_forward(activation, final_w, final_b, activation_fn = jax.nn.softmax)\n",
        "#         output = jax.nn.softmax(logits)\n",
        "#         self.caches.append(cache)\n",
        "\n",
        "#         return output\n",
        "\n",
        "#     def forward(self,X):\n",
        "#         batch_forward = jit(vmap(self._forward, in_axes=(None, 0), out_axes=0))\n",
        "#         return batch_forward(X)\n",
        "\n",
        "#     def linear_backward(self, dZ, cache):\n",
        "#         \"\"\"\n",
        "#         Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "#         Arguments:\n",
        "#         dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "#         cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "\n",
        "#         Returns:\n",
        "#         dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "#         dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "#         db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "#         \"\"\"\n",
        "#         A_prev, W, b = cache\n",
        "#         m = A_prev.shape[1]\n",
        "\n",
        "#         ### START CODE HERE ### (≈ 3 lines of code)\n",
        "#         dW = np.dot(dZ, cache[0].T) / m\n",
        "#         db = np.squeeze(np.sum(dZ, axis=1, keepdims=True)) / m\n",
        "#         dA_prev = np.dot(cache[1].T, dZ)\n",
        "#         ### END CODE HERE ###\n",
        "        \n",
        "#         assert (dA_prev.shape == A_prev.shape)\n",
        "#         assert (dW.shape == W.shape)\n",
        "#         assert (isinstance(db, float))\n",
        "        \n",
        "#         return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "-fj3-RY18knO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "@jit\n",
        "def forward(params,in_array):\n",
        "    \"\"\"\n",
        "        Compute the forward pass for each example individually\n",
        "        params: list of weights and biases of MLP \n",
        "        x: single flat image\n",
        "    \"\"\"\n",
        "    hidden_layers = params[:-1]\n",
        "\n",
        "    activations = in_array\n",
        "\n",
        "    # Loop over the ReLU hidden layers\n",
        "    for w, b in hidden_layers:\n",
        "        a = np.dot(w,activations) + b \n",
        "        activation = jax.nn.relu(a)\n",
        "    \n",
        "    # Perform final trafo to logits\n",
        "    final_w, final_b = params[-1]\n",
        "    logits = np.dot(final_w, activations) + final_b\n",
        "    output = jax.nn.softmax(logits)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "oilnpAgI5Bya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update(params,imgs,labels):\n",
        "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
        "    value, grads = value_and_grad(loss)(params, x, y)\n"
      ],
      "metadata": {
        "id": "uzSY59J_P8th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_MLPClassfier(layer_sizes,parent_key,scale = 0.01):\n",
        "    params = []\n",
        "    keys = random.split(parent_key,num= len(layer_sizes) - 1)\n",
        "\n",
        "    for i in range(len(layer_sizes)-1):\n",
        "        w_key,b_key = random.split(keys[i])\n",
        "        in_size = layer_sizes[i]\n",
        "        out_size = layer_sizes[i+1]\n",
        "        w = random.normal(w_key,shape=(in_size,out_size))\n",
        "        b = random.normal(b_key,shape=(out_size,))\n",
        "        params.append([w,b])\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "2mBJQ5mR4jWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "input,h1,h2,output = (784,512,256,10)\n",
        "layers = [input,h1,h2,output]\n",
        "seed = 42 \n",
        "\n",
        "parent_key = random.PRNGKey(seed)\n",
        "MLP_params = init_MLPClassfier(layers,parent_key)\n",
        "\n",
        "print(jax.tree_map(lambda x: x.shape,MLP_params))"
      ],
      "metadata": {
        "id": "Xw5CXGtK41Zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}